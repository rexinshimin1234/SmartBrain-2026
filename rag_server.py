import uvicorn
from fastapi import FastAPI, UploadFile, File, HTTPException
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer, util
import os
import glob
import shutil
import httpx  # âœ… å¼•å…¥å¼‚æ­¥ HTTP å®¢æˆ·ç«¯
from typing import List, Dict, Optional

# --- 1. é…ç½®åŒºåŸŸ ---
API_KEY = "sk-4f5a33e749174b61969cea91ed09d4e0"
BASE_URL = "https://api.deepseek.com/chat/completions" # æ³¨æ„ï¼šhttpx éœ€è¦å®Œæ•´çš„ URL endpoints
DATA_DIR = "./data"

# --- 2. æ ¸å¿ƒç±»å®šä¹‰ (OOP å°è£…) ---

class KnowledgeBase:
    """
    çŸ¥è¯†åº“ç®¡ç†ç±»ï¼šè´Ÿè´£æ–‡ä»¶è¯»å–ã€å‘é‡åŒ–ã€æ£€ç´¢
    """
    def __init__(self, data_dir: str, model_path: str = './local_model'):
        self.data_dir = data_dir
        self.model = SentenceTransformer(model_path)
        self.documents = []   # å­˜æ–‡æœ¬
        self.sources = []     # å­˜æ–‡ä»¶å
        self.embeddings = None
        
        # åˆå§‹åŒ–æ—¶åŠ è½½
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        self.reload()

    def reload(self):
        """é‡æ–°æ‰«æå¹¶è®¡ç®—å‘é‡"""
        print(f"ğŸ”„ [KnowledgeBase] æ­£åœ¨æ‰«æ: {self.data_dir}")
        temp_docs = []
        temp_sources = []
        
        # æ‰«æ TXT
        for file_path in glob.glob(os.path.join(self.data_dir, "*.txt")):
            with open(file_path, "r", encoding="utf-8") as f:
                lines = [line.strip() for line in f if line.strip()]
                temp_docs.extend(lines)
                temp_sources.extend([os.path.basename(file_path)] * len(lines))
        
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºç®€æ´ï¼Œæš‚æ—¶çœç•¥ PDF é€»è¾‘ï¼Œä½ æŠŠä¹‹å‰çš„ PDF é€»è¾‘ç²˜å›æ¥å³å¯
        
        self.documents = temp_docs
        self.sources = temp_sources
        
        if self.documents:
            print("âš¡ [KnowledgeBase] æ­£åœ¨è®¡ç®—å‘é‡...")
            self.embeddings = self.model.encode(self.documents)
        else:
            self.embeddings = None
            
        print(f"âœ… [KnowledgeBase] åŠ è½½å®Œæ¯•ï¼Œå…± {len(self.documents)} æ¡çŸ¥è¯†")

    def search(self, query: str, top_k: int = 3):
        """æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£"""
        if not self.documents or self.embeddings is None:
            return None, None, 0.0

        query_vec = self.model.encode([query])
        hits = util.semantic_search(query_vec, self.embeddings, top_k=top_k)
        
        best = hits[0][0]
        idx = best['corpus_id']
        return self.documents[idx], self.sources[idx], best['score']

class DeepSeekClient:
    """
    AI å®¢æˆ·ç«¯ç±»ï¼šè´Ÿè´£ä¸ LLM è¿›è¡Œå¼‚æ­¥é€šä¿¡
    """
    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    async def chat_async(self, messages: List[Dict]):
        """
        âœ… å¼‚æ­¥å‘é€èŠå¤©è¯·æ±‚
        """
        payload = {
            "model": "deepseek-chat",
            "messages": messages,
            "stream": False
        }
        
        # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä¸ä¼šé˜»å¡ä¸»çº¿ç¨‹
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                resp = await client.post(self.base_url, headers=self.headers, json=payload)
                resp.raise_for_status() # å¦‚æœ 4xx/5xx ä¼šæŠ¥é”™
                return resp.json()['choices'][0]['message']['content']
            except Exception as e:
                print(f"âŒ API è¯·æ±‚å¤±è´¥: {e}")
                return "AI æ€è€ƒæ—¶æ–­çº¿äº†..."

# --- 3. å®ä¾‹åŒ–å…¨å±€å¯¹è±¡ (å•ä¾‹æ¨¡å¼) ---
# è¿™äº›å¯¹è±¡åœ¨åº”ç”¨å¯åŠ¨æ—¶åªåˆ›å»ºä¸€æ¬¡
kb = KnowledgeBase(DATA_DIR)
ai_client = DeepSeekClient(API_KEY, BASE_URL)

app = FastAPI()

class QueryRequest(BaseModel):
    # æ ‡å‡†çš„ OpenAI æ ¼å¼: [{"role": "user", "content": "..."}]
    messages: List[Dict[str, str]]

# --- 4. æ¥å£å®ç° ---

@app.post("/chat")
async def chat_endpoint(request: QueryRequest):
    # 1. è·å–ç”¨æˆ·æœ€æ–°çš„é—®é¢˜
    if not request.messages:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º")
    
    user_query = request.messages[-1]["content"]
    
    # 2. æ£€ç´¢çŸ¥è¯†åº“ (RAG)
    # ç®€å•ç­–ç•¥ï¼šç›´æ¥ç”¨æœ€æ–°é—®é¢˜å»æœã€‚
    # è¿›é˜¶ç­–ç•¥(ä½ ä¹‹å‰çš„): ç”¨ä¸Šä¸‹æ–‡å»æœã€‚è¿™é‡Œå…ˆä¿æŒç®€å•ï¼Œç¡®ä¿ä»£ç è·‘é€šã€‚
    retrieved_text, source_file, score = kb.search(user_query)
    
    # 3. æ„å»º Prompt
    # æŠ€å·§ï¼šæˆ‘ä»¬å°†â€œå‚è€ƒèµ„æ–™â€æ”¾å…¥ System Promptï¼Œè¿™æ · AI ä¼šè®°å¾—æ›´ç‰¢ï¼Œè€Œä¸”ä¸ç ´å messages ç»“æ„
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å·¥ä¸šåŠ©æ‰‹ã€‚å›ç­”é—®é¢˜æ—¶è¯·å‚è€ƒä»¥ä¸‹èµ„æ–™ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·è¯šå®å‘ŠçŸ¥ã€‚"
    if retrieved_text and score > 0.35:
        system_prompt += f"\n\nã€å‚è€ƒèµ„æ–™ã€‘(æ¥æº: {source_file}):\n{retrieved_text}"
    else:
        system_prompt += "\n\n(æš‚æ— ç›¸å…³å‚è€ƒèµ„æ–™ï¼Œè¯·å‡­å¸¸è¯†å›ç­”)"

    # 4. ç»„è£…æœ€ç»ˆçš„æ¶ˆæ¯åˆ—è¡¨
    # ç»“æ„ï¼š[System(å¸¦èµ„æ–™), User, Assistant, User...]
    full_messages = [{"role": "system", "content": system_prompt}] + request.messages

    # 5. âœ… å¼‚æ­¥è°ƒç”¨ AI
    print(f"ğŸ“¨ å‘é€è¯·æ±‚ç»™ DeepSeek... (åŒ…å« {len(full_messages)} æ¡å†å²)")
    answer = await ai_client.chat_async(full_messages)
    
    return {
        "answer": answer,
        "source": source_file if score > 0.35 else "æ— ",
        "score": float(score)
    }

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    file_location = os.path.join(DATA_DIR, file.filename)
    with open(file_location, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    # è°ƒç”¨å¯¹è±¡çš„æ–¹æ³•çƒ­æ›´æ–°
    kb.reload()
    
    return {"message": f"æ–‡ä»¶ {file.filename} ä¸Šä¼ æˆåŠŸï¼ŒçŸ¥è¯†åº“å·²åˆ·æ–°ã€‚"}

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)